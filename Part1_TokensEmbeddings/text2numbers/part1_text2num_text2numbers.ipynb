{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBsNRoJ8HpGk"
   },
   "source": [
    "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
    "|-|:-:|\n",
    "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n",
    "|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n",
    "|<h2>Lecture:</h2>|<h1><b>Parsing text to numbered tokens<b></h1>|\n",
    "\n",
    "<br>\n",
    "\n",
    "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
    "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
    "<i>Using the code without the course may lead to confusion or errors.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KDVo9UpRHuaY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcl6mvSJ0z6H"
   },
   "source": [
    "# Parsing text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RmFWYsyFHuXT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All that we are is the result of what we have thought',\n",
       " 'To be or not to be that is the question',\n",
       " 'Be yourself everyone else is already taken']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the text\n",
    "text = [ 'All that we are is the result of what we have thought',\n",
    "         'To be or not to be that is the question',\n",
    "         'Be yourself everyone else is already taken' ]\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "83q3ZHR6HuSd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_2145/1325930493.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  re.split('\\s',text[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['All',\n",
       " 'that',\n",
       " 'we',\n",
       " 'are',\n",
       " 'is',\n",
       " 'the',\n",
       " 'result',\n",
       " 'of',\n",
       " 'what',\n",
       " 'we',\n",
       " 'have',\n",
       " 'thought']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate into words by splitting by spaces\n",
    "import re\n",
    "re.split('\\s',text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F3xIl0TZHuPx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_2145/1857155964.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  ' '.join( re.split('\\s',text[0]) )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All that we are is the result of what we have thought'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can recombine into a text\n",
    "' '.join( re.split('\\s',text[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jMgUhoFJFCo"
   },
   "outputs": [],
   "source": [
    "# also make lower-case\n",
    "allwords = re.split('\\s',' '.join(text).lower())\n",
    "allwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWjXaGF40-Y2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3vIFNqe0-V7"
   },
   "source": [
    "# Create a vocabulary (lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xt6qDnGvHuNA"
   },
   "outputs": [],
   "source": [
    "# find the unique words\n",
    "vocab = sorted(set(allwords))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJIoqHSLHuHL"
   },
   "outputs": [],
   "source": [
    "print(f'There are {len(allwords)} words in the text, and {len(vocab)} words in the vocabulary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LNdk--11DH9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQOK9BE31DDd"
   },
   "source": [
    "# Create an encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQk8dGyBHuEc"
   },
   "outputs": [],
   "source": [
    "# the encoder is a python dictionary type\n",
    "word2idx = {}\n",
    "for i,word in enumerate(vocab):\n",
    "  word2idx[word] = i\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqKALTBaHuBa"
   },
   "outputs": [],
   "source": [
    "# and a decoder\n",
    "idx2word = {}\n",
    "for i,word in enumerate(vocab):\n",
    "  idx2word[i] = word\n",
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTR0BMxdHt-l"
   },
   "outputs": [],
   "source": [
    "print(f'The word \"to\" has index {word2idx[\"to\"]}')\n",
    "print(f'The index \"7\" maps to the word \"{idx2word[7]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1VfwvVt1NUz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GULhYnOP1NSA"
   },
   "source": [
    "# Make fake quotes, just for fun :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGCwhK-GHt8B"
   },
   "outputs": [],
   "source": [
    "# select random words from the dictionary\n",
    "import numpy as np\n",
    "randidx = np.random.randint(0,len(vocab),size=5)\n",
    "\n",
    "# words of wisdom as a list of tokens\n",
    "[ idx2word[i] for i in randidx ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0QzTDjSUU-E"
   },
   "outputs": [],
   "source": [
    "# does it sound more wise as text??\n",
    "' '.join([ idx2word[i] for i in randidx ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0StRY37I1dwU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X2k966q1dpW"
   },
   "source": [
    "# A peek at tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLBJ8ijaL5um"
   },
   "outputs": [],
   "source": [
    "# translate the text into numbers\n",
    "text_as_int = [ word2idx[word] for word in allwords ]\n",
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9VtmaEb15kX"
   },
   "outputs": [],
   "source": [
    "# and numbers back into text\n",
    "for tokeni in text_as_int:\n",
    "  print(f'Token {tokeni:2}: {idx2word[tokeni]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beWoY-qYOyLn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".env_LLM",
   "language": "python",
   "name": ".env_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
